import {useCallback, useRef, useState} from 'react'
const formatDateTime = () => {
    const now = new Date();
    const pad = (num) => String(num).padStart(2, '0');
    const yyyy = now.getFullYear();
    const MM = pad(now.getMonth() + 1);
    const dd = pad(now.getDate());
    const HH = pad(now.getHours());
    const mm = pad(now.getMinutes());
    const ss = pad(now.getSeconds());
    return `${yyyy}${MM}${dd}_${HH}${mm}${ss}`;
};

export function useChatSSE({url, headers = {}, botId = '7586122118481002502'}) {
    const [messages, setMessages] = useState<any[]>([])
    const [loading, setLoading] = useState(false)
    const [error, setError] = useState<string | null>(null)
    const [isAudioPlaying, setIsAudioPlaying] = useState(false)
   const isConversationRef = useRef<boolean>(false)
    const  conversationIdRef = useRef<number>('')
    const controllerRef = useRef<AbortController | null>(null)
    const assistantIdRef = useRef<string | null>(null)
    const chatIdRef = useRef<string | null>(null)
    const userIdRef = useRef<number | null>(null)

    // éŸ³é¢‘ç›¸å…³çš„ refs
    const audioContextRef = useRef<AudioContext | null>(null)
    const audioBuffersRef = useRef<AudioBuffer[]>([])
    const audioSourceRef = useRef<AudioBufferSourceNode | null>(null)
    const isPlayingAudioRef = useRef(false)
    const nextPlayTimeRef = useRef(0)

    // åˆå§‹åŒ– AudioContext
    const initAudioContext = () => {
        if (!audioContextRef.current) {
            const AudioCtx = window.AudioContext || (window as any).webkitAudioContext
            audioContextRef.current = new AudioCtx()
            nextPlayTimeRef.current = 0
        }
        return audioContextRef.current
    }

    // å®æ—¶æ’­æ”¾éŸ³é¢‘æ•°æ®å—
    const playAudioChunkRealtime = async (base64AudioStr: string) => {
        try {
            console.log(`ğŸµ æ”¶åˆ°éŸ³é¢‘å—ï¼Œé•¿åº¦: ${base64AudioStr?.length}`)

            // è§£ç  base64
            const binaryString = atob(base64AudioStr)
            const pcmBytes: number[] = []

            for (let j = 0; j < binaryString.length; j++) {
                pcmBytes.push(binaryString.charCodeAt(j))
            }

            // è½¬æ¢ä¸º int16 PCM æ•°æ®
            const pcmData = new Int16Array(pcmBytes.length / 2)
            for (let i = 0; i < pcmBytes.length; i += 2) {
                if (i + 1 < pcmBytes.length) {
                    const low = pcmBytes[i]
                    const high = pcmBytes[i + 1]
                    pcmData[i / 2] = (low | (high << 8)) << 16 >> 16
                }
            }

            // è½¬æ¢ä¸º Float32Array
            const float32Data = new Float32Array(pcmData.length)
            for (let i = 0; i < pcmData.length; i++) {
                float32Data[i] = pcmData[i] / 32768.0
            }

            // åˆå§‹åŒ– AudioContext
            const audioContext = initAudioContext()

            // åˆ›å»º AudioBuffer
            const sampleRate = 24000
            const numChannels = 1
            const audioBuffer = audioContext.createBuffer(numChannels, float32Data.length, sampleRate)
            audioBuffer.getChannelData(0).set(float32Data)

            // åˆ›å»ºéŸ³é¢‘æº
            const source = audioContext.createBufferSource()
            source.buffer = audioBuffer
            source.connect(audioContext.destination)

            // è®¡ç®—æ’­æ”¾æ—¶é—´
            const currentTime = audioContext.currentTime
            const startTime = Math.max(currentTime, nextPlayTimeRef.current)

            // ç¬¬ä¸€ä¸ªéŸ³é¢‘å—
            if (!isPlayingAudioRef.current) {
                console.log(`ğŸµ å¼€å§‹æ’­æ”¾ç¬¬ä¸€ä¸ªéŸ³é¢‘å—ï¼Œæ—¶é•¿: ${audioBuffer.duration.toFixed(3)} ç§’`)
                isPlayingAudioRef.current = true
                setIsAudioPlaying(true)
                nextPlayTimeRef.current = currentTime + audioBuffer.duration
            } else {
                console.log(`ğŸµ è¿ç»­æ’­æ”¾éŸ³é¢‘å—ï¼Œæ—¶é•¿: ${audioBuffer.duration.toFixed(3)} ç§’ï¼Œè°ƒåº¦æ—¶é—´: ${(startTime - currentTime).toFixed(3)} ç§’å`)
                nextPlayTimeRef.current = startTime + audioBuffer.duration
            }

            // æ’­æ”¾
            source.start(startTime)
            audioSourceRef.current = source

            // ç›‘å¬æ’­æ”¾ç»“æŸ
            source.onended = () => {
                console.log('ğŸµ éŸ³é¢‘å—æ’­æ”¾å®Œæˆ')
            }

        } catch (error) {
            console.error('âŒ éŸ³é¢‘å—æ’­æ”¾å¤±è´¥:', error)
        }
    }

    // å®ŒæˆéŸ³é¢‘æ’­æ”¾
    const finishAudioPlayback = () => {
        // ç­‰å¾…æ‰€æœ‰éŸ³é¢‘å—æ’­æ”¾å®Œæˆ
        const audioContext = audioContextRef.current
        if (audioContext && isPlayingAudioRef.current) {
            const waitTime = Math.max(0, nextPlayTimeRef.current - audioContext.currentTime)
            console.log(`ğŸµ ç­‰å¾…æœ€åçš„éŸ³é¢‘å—æ’­æ”¾å®Œæˆï¼Œå‰©ä½™æ—¶é—´: ${waitTime.toFixed(3)} ç§’`)

            setTimeout(() => {
                console.log('ğŸµ æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ')
                isPlayingAudioRef.current = false
                setIsAudioPlaying(false)
                nextPlayTimeRef.current = 0
            }, waitTime * 1000)
        }
    }

    // åœæ­¢éŸ³é¢‘æ’­æ”¾
    const stopAudio = () => {
        const wasPlaying = isPlayingAudioRef.current
        if (audioSourceRef.current) {
            try {
                audioSourceRef.current.stop()
                console.log('âš ï¸ éŸ³é¢‘æ’­æ”¾è¢«æ‰‹åŠ¨åœæ­¢')
            } catch (e) {
                // å¿½ç•¥å·²ç»åœæ­¢çš„é”™è¯¯
            }
            audioSourceRef.current = null
        }
        if (wasPlaying) {
            console.log('âš ï¸ æ¸…ç©ºéŸ³é¢‘æ’­æ”¾çŠ¶æ€ï¼ˆæ’­æ”¾æœªå®Œæˆï¼‰')
        }
        isPlayingAudioRef.current = false
        setIsAudioPlaying(false)
        nextPlayTimeRef.current = 0
    }

    const start = useCallback(async (userMessage) => {
        controllerRef.current?.abort()

        const controller = new AbortController()
        controllerRef.current = controller

        // åœæ­¢ä¹‹å‰çš„éŸ³é¢‘æ’­æ”¾å¹¶æ¸…ç©ºéŸ³é¢‘æ•°æ®
        stopAudio()

        setLoading(true)
        setError(null)

        // âœ… 1. æ¨å…¥ user æ¶ˆæ¯
        setMessages(prev => [...prev, userMessage])

        // âœ… 2. å‡†å¤‡ assistant å ä½
        const assistantId = crypto.randomUUID()
        assistantIdRef.current = assistantId

        setMessages(prev => [
            ...prev,
            {
                id: assistantId,
                role: 'ai',
                type: 'answer',
                content: '',
                content_type: 'text'
            }
        ])

        // å§‹ç»ˆä½¿ç”¨ object_string æ ¼å¼
        let requestMessageArr = []

        // æ„å»ºæ¶ˆæ¯å†…å®¹æ•°ç»„ï¼Œå§‹ç»ˆåŒ…å«æ–‡å­—éƒ¨åˆ†
        let arr = [{
            type: 'text',
            text: userMessage?.content || '',
        }]

        // å¦‚æœæœ‰é™„ä»¶ï¼ˆå›¾ç‰‡æˆ–éŸ³é¢‘ï¼‰ï¼Œè¿½åŠ åˆ°æ•°ç»„ä¸­
        if (userMessage?.imageUrls && userMessage?.imageUrls.length) {
            userMessage.imageUrls.forEach(x => {
                let obj = {
                    type: x.isAudio ? 'audio' : 'file', // æ ¹æ®æ˜¯å¦ä¸ºéŸ³é¢‘æ–‡ä»¶ä½¿ç”¨ä¸åŒçš„ type
                }
                obj['file_id'] = x.response.id
                console.log('ğŸ“ æ·»åŠ æ–‡ä»¶åˆ°æ¶ˆæ¯:', { type: obj.type, file_id: obj['file_id'], isAudio: x.isAudio })
                arr.push(obj)
            })
        }

        // å§‹ç»ˆä½¿ç”¨ object_string æ ¼å¼
        requestMessageArr.push({
            role: userMessage.role,
            content_type: 'object_string',
            content: JSON.stringify(arr)
        })

        const requestUrl =  `${url}?conversation_id=${conversationIdRef.current}`
        userIdRef.current = userIdRef.current || formatDateTime()

        const requestBody = {
            bot_id: botId,
            user_id:userIdRef.current,
            stream: true,
            auto_save_history: true,
            parameters: {
                user: [
                    {
                        user_id: userIdRef.current,
                        user_name: "user"
                    }
                ]
            },
            additional_messages: requestMessageArr,
            // æ·»åŠ éŸ³é¢‘è¾“å‡ºé…ç½®ï¼Œç¡®ä¿æœåŠ¡å™¨è¿”å›éŸ³é¢‘æµ
            output_audio: {
                voice_id: '7426725529589661723', // æŒ‡å®šéŸ³è‰² ID
                format: 'pcm' // éŸ³é¢‘æ ¼å¼
            }
        }

        try {
            const response = await fetch(requestUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    "Authorization": 'Bearer pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE',
                    ...headers
                },
                body: JSON.stringify(requestBody),
                signal: controller.signal
            })

            // æ£€æŸ¥å“åº”çŠ¶æ€
            if (!response.ok) {
                const errorText = await response.text()
                console.error('è¯·æ±‚å¤±è´¥:', response.status, errorText)
                try {
                    const errorJson = JSON.parse(errorText)
                    setError(errorJson.msg || `è¯·æ±‚å¤±è´¥: ${response.status}`)
                } catch {
                    setError(`è¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
                }
                setLoading(false)
                controller.abort()
                return
            }

            const reader = response.body!.getReader()
            const decoder = new TextDecoder()

            let buffer = ''

            while (true) {
                const {value, done} = await reader.read()
                if (done) break

                buffer += decoder.decode(value, {stream: true})
                const events = buffer.split('\n\n')
                buffer = events.pop() || ''

                for (const raw of events) {
                    if (!raw.trim()) continue

                    const lines = raw.split('\n')
                    const event = lines.find(l => l.startsWith('event:'))?.slice(6).trim()
                    const dataLine = lines.find(l => l.startsWith('data:'))

                    if (!dataLine) continue
                    const dataRaw = dataLine.slice(5).trim()

                    // âœ… DONE
                    if (dataRaw === '"[DONE]"') {
                        setLoading(false)
                        controller.abort()
                        return
                    }

                    const data = JSON.parse(dataRaw)
        if(!isConversationRef.current){
            conversationIdRef.current = data.conversation_id
            isConversationRef.current = true
        }

                    switch (event) {
                        case 'conversation.chat.created':
                            chatIdRef.current = data.id
                            break

                        case 'conversation.message.delta':
                            if (data.content) {
                                setMessages(prev =>
                                    prev.map(m =>
                                        m.id === assistantIdRef.current
                                            ? {
                                                ...m,
                                                content: m.content + data.content,
                                                chat_id: data.chat_id,
                                                section_id: data.section_id
                                            }
                                            : m
                                    )
                                )
                            }
                            break

                        case 'conversation.audio.delta':
                            // éŸ³é¢‘æµå¼æ•°æ® - å®æ—¶æ’­æ”¾
                            if (data.content) {
                                playAudioChunkRealtime(data.content)
                            }
                            break

                        case 'conversation.message.completed':
                            // âœ… å•æ¡æ¶ˆæ¯å®Œæˆï¼ˆä¸€èˆ¬å¯å¿½ç•¥ï¼‰
                            break

                        case 'conversation.chat.completed':
                            // å¯¹è¯å®Œæˆåï¼Œç¡®ä¿æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ
                            finishAudioPlayback()
                            setLoading(false)
                            controller.abort()
                            return

                        case 'conversation.chat.failed':
                            setError(data?.last_error?.msg || 'å¯¹è¯å¤±è´¥')
                            setLoading(false)
                            controller.abort()
                            return

                        default:
                            break
                    }
                }
            }
        } catch (err: any) {
            if (err.name !== 'AbortError') {
                setError('ç½‘ç»œæˆ–æœåŠ¡å¼‚å¸¸')
                setLoading(false)
            }
        }
    }, [url, headers])

    const stop = useCallback(() => {
        controllerRef.current?.abort()
        setLoading(false)
    }, [])

    // æ¸…ç©ºå¯¹è¯å†å²ï¼Œå¼€å§‹æ–°å¯¹è¯
    const reset = useCallback(() => {
        controllerRef.current?.abort()
        stopAudio() // åœæ­¢éŸ³é¢‘æ’­æ”¾
        setMessages([])
        setLoading(false)
        setError(null)
        isConversationRef.current = false
        conversationIdRef.current = ''
        assistantIdRef.current = null
        chatIdRef.current = null
        // æ³¨æ„ï¼šä¸é‡ç½® userIdRefï¼Œä¿æŒç”¨æˆ· ID ä¸€è‡´
    }, [])

    return {
        messages,
        loading,
        error,
        isAudioPlaying,
        start,
        stop,
        reset,
        stopAudio
    }
}
