import {useCallback, useRef, useState} from 'react'

const formatDateTime = () => {
    const now = new Date();
    const pad = (num) => String(num).padStart(2, '0');
    const yyyy = now.getFullYear();
    const MM = pad(now.getMonth() + 1);
    const dd = pad(now.getDate());
    const HH = pad(now.getHours());
    const mm = pad(now.getMinutes());
    const ss = pad(now.getSeconds());
    return `${yyyy}${MM}${dd}_${HH}${mm}${ss}`;
};

export function useChatSSE({url, headers = {}, botId = '7586122118481002502'}) {
    const [messages, setMessages] = useState<any[]>([])
    const [loading, setLoading] = useState(false)
    const [error, setError] = useState<string | null>(null)
    const [isAudioPlaying, setIsAudioPlaying] = useState(false)
    const isConversationRef = useRef<boolean>(false)
    const conversationIdRef = useRef<number>('')
    const controllerRef = useRef<AbortController | null>(null)
    const assistantIdRef = useRef<string | null>(null)
    const chatIdRef = useRef<string | null>(null)
    const userIdRef = useRef<number | null>(null)

    // éŸ³é¢‘ç›¸å…³çš„ refs
    const audioContextRef = useRef<AudioContext | null>(null)
    const audioSourceRef = useRef<AudioBufferSourceNode | null>(null)
    const isPlayingAudioRef = useRef(false)
    const nextPlayTimeRef = useRef(0)
    const isAudioStoppedByUserRef = useRef(false) // æ ‡è®°ç”¨æˆ·æ˜¯å¦æ‰‹åŠ¨åœæ­¢äº†æ’­æ”¾
    const activeSourcesRef = useRef<Set<AudioBufferSourceNode>>(new Set()) // è·Ÿè¸ªæ‰€æœ‰å·²è°ƒåº¦çš„éŸ³é¢‘æº

    // åˆå§‹åŒ– AudioContext
    const initAudioContext = () => {
        // å¦‚æœä¹‹å‰è¢« closeï¼Œéœ€è¦é‡æ–°åˆ›å»º
        if (audioContextRef.current && audioContextRef.current.state === 'closed') {
            audioContextRef.current = null
        }

        if (!audioContextRef.current) {
            const AudioCtx = window.AudioContext || (window as any).webkitAudioContext
            audioContextRef.current = new AudioCtx()
            nextPlayTimeRef.current = 0
        }
        return audioContextRef.current
    }

    // å®æ—¶æ’­æ”¾éŸ³é¢‘æ•°æ®å—
    const playAudioChunkRealtime = async (base64AudioStr: string) => {
        // å¦‚æœç”¨æˆ·å·²æ‰‹åŠ¨åœæ­¢æ’­æ”¾ï¼Œåˆ™ä¸å†æ’­æ”¾æ–°çš„éŸ³é¢‘å—
        if (isAudioStoppedByUserRef.current) {
            console.log('â¸ï¸ ç”¨æˆ·å·²åœæ­¢æ’­æ”¾ï¼Œå¿½ç•¥æ–°çš„éŸ³é¢‘å—')
            return
        }

        try {
            console.log(`ğŸµ æ”¶åˆ°éŸ³é¢‘å—ï¼Œé•¿åº¦: ${base64AudioStr?.length}`)

            // è§£ç  base64
            const binaryString = atob(base64AudioStr)
            const pcmBytes: number[] = []

            for (let j = 0; j < binaryString.length; j++) {
                pcmBytes.push(binaryString.charCodeAt(j))
            }

            // è½¬æ¢ä¸º int16 PCM æ•°æ®
            const pcmData = new Int16Array(pcmBytes.length / 2)
            for (let i = 0; i < pcmBytes.length; i += 2) {
                if (i + 1 < pcmBytes.length) {
                    const low = pcmBytes[i]
                    const high = pcmBytes[i + 1]
                    pcmData[i / 2] = (low | (high << 8)) << 16 >> 16
                }
            }

            // è½¬æ¢ä¸º Float32Array
            const float32Data = new Float32Array(pcmData.length)
            for (let i = 0; i < pcmData.length; i++) {
                float32Data[i] = pcmData[i] / 32768.0
            }

            // åˆå§‹åŒ– AudioContext
            const audioContext = initAudioContext()
            if (audioContext.state === 'suspended') {
                try {
                    await audioContext.resume()
                } catch (_) {
                    // resume å¤±è´¥æ—¶å…ˆå¿½ç•¥ï¼Œåç»­ç‰‡æ®µä»ä¼šå°è¯•æ’­æ”¾
                }
            }

            // åˆ›å»º AudioBuffer
            const sampleRate = 24000
            const numChannels = 1
            const audioBuffer = audioContext.createBuffer(numChannels, float32Data.length, sampleRate)
            audioBuffer.getChannelData(0).set(float32Data)

            // åˆ›å»ºéŸ³é¢‘æº
            const source = audioContext.createBufferSource()
            source.buffer = audioBuffer
            source.connect(audioContext.destination)
            activeSourcesRef.current.add(source)

            // è®¡ç®—æ’­æ”¾æ—¶é—´
            const currentTime = audioContext.currentTime
            const startTime = Math.max(currentTime, nextPlayTimeRef.current)

            // ç¬¬ä¸€ä¸ªéŸ³é¢‘å—
            if (!isPlayingAudioRef.current) {
                console.log(`ğŸµ å¼€å§‹æ’­æ”¾ç¬¬ä¸€ä¸ªéŸ³é¢‘å—ï¼Œæ—¶é•¿: ${audioBuffer.duration.toFixed(3)} ç§’`)
                isPlayingAudioRef.current = true
                setIsAudioPlaying(true)
                nextPlayTimeRef.current = currentTime + audioBuffer.duration
            } else {
                console.log(`ğŸµ è¿ç»­æ’­æ”¾éŸ³é¢‘å—ï¼Œæ—¶é•¿: ${audioBuffer.duration.toFixed(3)} ç§’ï¼Œè°ƒåº¦æ—¶é—´: ${(startTime - currentTime).toFixed(3)} ç§’å`)
                nextPlayTimeRef.current = startTime + audioBuffer.duration
            }

            // æ’­æ”¾
            source.start(startTime)
            audioSourceRef.current = source

            // ç›‘å¬æ’­æ”¾ç»“æŸ
            source.onended = () => {
                console.log('ğŸµ éŸ³é¢‘å—æ’­æ”¾å®Œæˆ')
                activeSourcesRef.current.delete(source)
                // æ‰€æœ‰ç‰‡æ®µç»“æŸåé‡ç½®çŠ¶æ€ï¼Œé¿å… stop åæ— æ³•é‡æ–°æ’­æ”¾
                if (activeSourcesRef.current.size === 0) {
                    isPlayingAudioRef.current = false
                    setIsAudioPlaying(false)
                    nextPlayTimeRef.current = 0
                }
            }

        } catch (error) {
            console.error('âŒ éŸ³é¢‘å—æ’­æ”¾å¤±è´¥:', error)
        }
    }


    // åœæ­¢éŸ³é¢‘æ’­æ”¾
    const stopAudio = () => {
        const wasPlaying = isPlayingAudioRef.current

        // æ ‡è®°ç”¨æˆ·å·²æ‰‹åŠ¨åœæ­¢æ’­æ”¾ï¼Œé˜»æ­¢æ–°çš„éŸ³é¢‘å—æ’­æ”¾
        isAudioStoppedByUserRef.current = true
        console.log('â¸ï¸ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢æ’­æ”¾ï¼Œå·²è®¾ç½®é˜»æ­¢æ ‡å¿—')

        // åœæ­¢æ‰€æœ‰å·²è°ƒåº¦çš„éŸ³é¢‘æºï¼Œé¿å…æœªæ¥æ—¶é—´çº¿ç»§ç»­æ’­æ”¾
        activeSourcesRef.current.forEach(src => {
            try {
                src.stop()
            } catch (_) {
                // å·²åœæ­¢çš„èŠ‚ç‚¹å¯èƒ½æŠ›é”™ï¼Œå¿½ç•¥
            }
        })
        activeSourcesRef.current.clear()
        audioSourceRef.current = null

        // å…³é—­ AudioContext å¯ç«‹å³å–æ¶ˆå‰©ä½™è°ƒåº¦ï¼Œä¸‹ä¸€æ¬¡æ’­æ”¾ä¼šé‡å»º
        if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
            audioContextRef.current.close().catch(() => {
            })
        }
        audioContextRef.current = null

        if (wasPlaying) {
            console.log('âš ï¸ æ¸…ç©ºéŸ³é¢‘æ’­æ”¾çŠ¶æ€ï¼ˆæ’­æ”¾æœªå®Œæˆï¼‰')
        }
        isPlayingAudioRef.current = false
        setIsAudioPlaying(false)
        nextPlayTimeRef.current = 0
    }

    const start = useCallback(async (userMessage, options?: { prepareFiles?: () => Promise<any[]> }) => {
        controllerRef.current?.abort()

        const controller = new AbortController()
        controllerRef.current = controller

        // åœæ­¢ä¹‹å‰çš„éŸ³é¢‘æ’­æ”¾å¹¶æ¸…ç©ºéŸ³é¢‘æ•°æ®
        stopAudio()

        // é‡ç½®æ‰‹åŠ¨åœæ­¢æ ‡å¿—ï¼Œå…è®¸æ–°å¯¹è¯çš„éŸ³é¢‘æ’­æ”¾
        isAudioStoppedByUserRef.current = false
        console.log('ğŸ”„ å¼€å§‹æ–°å¯¹è¯ï¼Œé‡ç½®éŸ³é¢‘åœæ­¢æ ‡å¿—')

        setLoading(true)
        setError(null)

        // âœ… 1. æ¨å…¥ user æ¶ˆæ¯
        setMessages(prev => [...prev, userMessage])

        // âœ… 2. å‡†å¤‡ assistant å ä½
        const assistantId = crypto.randomUUID()
        assistantIdRef.current = assistantId

        setMessages(prev => [
            ...prev,
            {
                id: assistantId,
                role: 'ai',
                type: 'answer',
                content: '',
                content_type: 'text'
            }
        ])

        // âœ… 3. ç­‰å¾…é™„ä»¶å‡†å¤‡ï¼ˆä¸Šä¼ éŸ³é¢‘/å›¾ç‰‡ï¼‰
        let resolvedFiles: any[] = []
        if (options?.prepareFiles) {
            try {
                const prepared = await options.prepareFiles()
                if (Array.isArray(prepared)) {
                    resolvedFiles = prepared.filter(Boolean)
                }
            } catch (err) {
                console.error('é™„ä»¶å‡†å¤‡å¤±è´¥', err)
                setError('é™„ä»¶ä¸Šä¼ å¤±è´¥')
                setLoading(false)
                controller.abort()
                return
            }
        } else {
            resolvedFiles = userMessage?.imageUrls || []
        }

        // ç®€å•å»é‡ï¼šä¼˜å…ˆä½¿ç”¨ response.id å…¶æ¬¡ uid/name
        const seen = new Set<string>()
        resolvedFiles = resolvedFiles.filter(f => {
            const key = f?.response?.id || f?.uid || f?.name
            if (!key) return true
            if (seen.has(key)) return false
            seen.add(key)
            return true
        })

        // å§‹ç»ˆä½¿ç”¨ object_string æ ¼å¼
        let requestMessageArr = []

        // æ„å»ºæ¶ˆæ¯å†…å®¹æ•°ç»„ï¼Œå§‹ç»ˆåŒ…å«æ–‡å­—éƒ¨åˆ†
        let arr = [{
            type: 'text',
            text: userMessage?.content || '',
        }]
        console.log("resolvedFiles============>", resolvedFiles)
        // å¦‚æœæœ‰é™„ä»¶ï¼ˆå›¾ç‰‡æˆ–éŸ³é¢‘ï¼‰ï¼Œè¿½åŠ åˆ°æ•°ç»„ä¸­
        if (resolvedFiles && resolvedFiles.length) {
            resolvedFiles.forEach(x => {
                let obj = {
                    type: x.isAudio ? 'audio' : 'file', // æ ¹æ®æ˜¯å¦ä¸ºéŸ³é¢‘æ–‡ä»¶ä½¿ç”¨ä¸åŒçš„ type
                }
                obj['file_id'] = x.response.id
                console.log('ğŸ“ æ·»åŠ æ–‡ä»¶åˆ°æ¶ˆæ¯:', {type: obj.type, file_id: obj['file_id'], isAudio: x.isAudio})
                arr.push(obj)
            })
        }

        // å§‹ç»ˆä½¿ç”¨ object_string æ ¼å¼
        requestMessageArr.push({
            role: userMessage.role,
            content_type: 'object_string',
            content: JSON.stringify(arr)
        })

        const requestUrl = `${url}?conversation_id=${conversationIdRef.current}`
        userIdRef.current = userIdRef.current || formatDateTime()

        const requestBody = {
            bot_id: botId,
            user_id: userIdRef.current,
            stream: true,
            auto_save_history: true,
            parameters: {
                user: [
                    {
                        user_id: userIdRef.current,
                        user_name: "user"
                    }
                ]
            },
            additional_messages: requestMessageArr,
            // æ·»åŠ éŸ³é¢‘è¾“å‡ºé…ç½®ï¼Œç¡®ä¿æœåŠ¡å™¨è¿”å›éŸ³é¢‘æµ
            output_audio: {
                voice_id: '7426725529589661723', // æŒ‡å®šéŸ³è‰² ID
                format: 'pcm' // éŸ³é¢‘æ ¼å¼
            }
        }

        try {
            const response = await fetch(requestUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    "Authorization": 'Bearer pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE',
                    ...headers
                },
                body: JSON.stringify(requestBody),
                signal: controller.signal
            })

            // æ£€æŸ¥å“åº”çŠ¶æ€
            if (!response.ok) {
                const errorText = await response.text()
                console.error('è¯·æ±‚å¤±è´¥:', response.status, errorText)
                try {
                    const errorJson = JSON.parse(errorText)
                    setError(errorJson.msg || `è¯·æ±‚å¤±è´¥: ${response.status}`)
                } catch {
                    setError(`è¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
                }
                setLoading(false)
                controller.abort()
                return
            }

            const reader = response.body!.getReader()
            const decoder = new TextDecoder()

            let buffer = ''

            while (true) {
                const {value, done} = await reader.read()
                if (done) break

                buffer += decoder.decode(value, {stream: true})
                const events = buffer.split('\n\n')
                buffer = events.pop() || ''

                for (const raw of events) {
                    if (!raw.trim()) continue

                    const lines = raw.split('\n')
                    const event = lines.find(l => l.startsWith('event:'))?.slice(6).trim()
                    const dataLine = lines.find(l => l.startsWith('data:'))

                    if (!dataLine) continue
                    const dataRaw = dataLine.slice(5).trim()

                    const data = JSON.parse(dataRaw)
                    if (!isConversationRef.current) {
                        conversationIdRef.current = data.conversation_id
                        isConversationRef.current = true
                    }

                    switch (event) {
                        case 'conversation.chat.created':
                            chatIdRef.current = data.id
                            break

                        case 'conversation.message.delta':
                            if (data.content) {
                                setMessages(prev =>
                                    prev.map(m =>
                                        m.id === assistantIdRef.current
                                            ? {
                                                ...m,
                                                content: m.content + data.content,
                                                chat_id: data.chat_id,
                                                section_id: data.section_id
                                            }
                                            : m
                                    )
                                )
                            }
                            break

                        case 'conversation.audio.delta':
                            // éŸ³é¢‘æµå¼æ•°æ® - å®æ—¶æ’­æ”¾
                            if (data.content) {
                                playAudioChunkRealtime(data.content)
                            }
                            break

                        case 'conversation.message.completed':
                            // âœ… å•æ¡æ¶ˆæ¯å®Œæˆï¼ˆä¸€èˆ¬å¯å¿½ç•¥ï¼‰
                            break
                        case 'conversation.chat.completed':
                            setLoading(false)
                            // ä¸ä¸»åŠ¨ä¸­æ–­è¿æ¥ï¼Œç­‰å¾…éŸ³é¢‘æµè‡ªç„¶ç»“æŸï¼Œé¿å…æˆªæ–­å‰©ä½™ç‰‡æ®µ
                            break

                        case 'conversation.chat.failed':
                            setError(data?.last_error?.msg || 'å¯¹è¯å¤±è´¥')
                            setLoading(false)
                            controller.abort()
                            return

                        default:
                            break
                    }
                }
            }
        } catch (err: any) {
            if (err.name !== 'AbortError') {
                setError('ç½‘ç»œæˆ–æœåŠ¡å¼‚å¸¸')
                setLoading(false)
            }
        }
    }, [url, headers])

    const stop = useCallback(() => {
        controllerRef.current?.abort()
        setLoading(false)
    }, [])

    // æ¸…ç©ºå¯¹è¯å†å²ï¼Œå¼€å§‹æ–°å¯¹è¯
    const reset = useCallback(() => {
        controllerRef.current?.abort()
        stopAudio() // åœæ­¢éŸ³é¢‘æ’­æ”¾
        isAudioStoppedByUserRef.current = false // é‡ç½®åœæ­¢æ ‡å¿—
        setMessages([])
        setLoading(false)
        setError(null)
        isConversationRef.current = false
        conversationIdRef.current = ''
        assistantIdRef.current = null
        chatIdRef.current = null
        // æ³¨æ„ï¼šä¸é‡ç½® userIdRefï¼Œä¿æŒç”¨æˆ· ID ä¸€è‡´
    }, [])

    return {
        messages,
        loading,
        error,
        isAudioPlaying,
        start,
        stop,
        reset,
        stopAudio
    }
}
