import React, {useState, useRef, useEffect} from 'react';
import {useNavigate, useLocation} from 'react-router-dom';
import {Home, Mic, Camera, Keyboard, User, Bot, Send, StopCircle, Volume1, Volume2, FileUp, MessageSquarePlus, Phone, PhoneOff} from 'lucide-react';
import {message, Upload, Image, Typography, Slider} from 'antd';
import {CloseCircleFilled, FileTextOutlined} from '@ant-design/icons';
import type {UploadFile, UploadProps} from 'antd';
const { Text } = Typography;
import markdownit from 'markdown-it';
import styles from './AIQA.module.scss';
import {
    AIDenoiserProcessorLevel,
    AIDenoiserProcessorMode,
    WsToolsUtils,
    WsTranscriptionClient
} from "@coze/api/ws-tools";

import { WebsocketsEventType, CozeAPI} from "@coze/api";
import { useChatSSE } from '../../hooks/useChatSSE'
import { CameraCaptureModal } from './CameraCaptureModal'

// å…¨å±€é…ç½®ç±»å‹å£°æ˜
declare global {
    interface Window {
        APP_CONFIG?: {
            voiceCallSilenceTimeout?: number;
        };
    }
}

// è·å–è¯­éŸ³é€šè¯é™é»˜æ£€æµ‹æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤ 1000ms
const getVoiceCallSilenceTimeout = () => {
    return window.APP_CONFIG?.voiceCallSilenceTimeout ?? 1000;
};
console.log("å½“å‰ç§’æ•°ä¸º", getVoiceCallSilenceTimeout() +'ç§’');

type InputMode = 'voice' | 'file' | 'camera' | 'text';
type VoiceStatus = 'idle' | 'recording' | 'processing';

interface Message {
    id: number | string;
    role: 'user' | 'ai' | 'system';
    content: string;
    imageUrl?: string;
    imageUrls?: string[];  // æ”¯æŒå¤šå¼ å›¾ç‰‡

    fileName?: string;
}

const md = markdownit({ html: true, breaks: true });

const renderMarkdown: any = (content) => {
    let result = content.trim()
    return <div dangerouslySetInnerHTML={{ __html: md.render(result) }} />;
};


const AIQA = () => {
    let timeerRef = useRef(null);
    useEffect(()=>{
        if(timeerRef.current){
            timeerRef.current = null
            clearTimeout(timeerRef.current);
        }else {
            timeerRef.current =   setInterval(()=>{
                const now = new Date();
                const hour = now.getHours();
                const minute = now.getMinutes();
                const second = now.getSeconds();
                console.log(`${hour}:${minute}:${second}`);

            },1000)
        }
    },[])


    const navigate = useNavigate();
    const location = useLocation();

    // ä»è·¯ç”±è·å– botIdï¼Œé»˜è®¤ä½¿ç”¨é¢„é—®è¯Šçš„ botId
    const botIdFromRoute = (location.state as { botId?: string })?.botId || '7574375637029273609';
    const pageTitle = botIdFromRoute === '7574375637029273609' ? 'ç—…å²é‡‡é›†å°åŠ©ç†' : 'æŠ¥å‘Šè§£è¯»å°åŠ©æ‰‹';

    // åˆ›å»º Coze API å®¢æˆ·ç«¯å®ä¾‹
    const cozeClient = useRef(new CozeAPI({
        token: 'pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE',
        allowPersonalAccessTokenInBrowser: true,
        baseURL: 'https://api.coze.cn',
    })).current;
    const recognizeResult = useRef<Message>({} as Message);
    const [currentMode, setCurrentMode] = useState<InputMode>('text');
    const [textInput, setTextInput] = useState('');
    const [voiceStatus, setVoiceStatus] = useState<VoiceStatus>('idle');
    const [fileList, setFileList] = useState<UploadFile[]>([]);
    const fileListRef = useRef<UploadFile[]>([]); // ä½¿ç”¨ ref è§£å†³é—­åŒ…é—®é¢˜
    const pressStartTimeRef = useRef<number | null>(null);
    const [selectedInputDevice, setSelectedInputDevice] = useState<string>('');
    const [hasPermission, setHasPermission] = useState<boolean | null>(null);
    const [denoiserSupported, setDenoiserSupported] = useState<boolean>(false);
    const [cameraModalVisible, setCameraModalVisible] = useState(false);
    const clientRef = useRef<WsTranscriptionClient>();
    const messageListRef = useRef<HTMLDivElement | null>(null);
    const audioRef = useRef<HTMLAudioElement | null>(null);
    const speechAbortRef = useRef<AbortController | null>(null);
    // Web Audio RMS è¯­éŸ³æ£€æµ‹ç›¸å…³
    const micStreamRef = useRef<MediaStream | null>(null);
    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const rmsDataArrayRef = useRef<Uint8Array | null>(null);
    const rmsRafRef = useRef<number | null>(null);
    const initialQuestionRef = useRef<string | null>(null);
    const [spokenMessageId, setSpokenMessageId] = useState<string | number | null>(null);
    const [voiceId, setVoiceId] = useState<string>('');
    // æ³¨æ„ï¼šisAudioPlaying ç°åœ¨ä» useChatSSE è·å–ï¼Œç”¨äºæœåŠ¡å™¨éŸ³é¢‘æµ
    const [audioVolume, setAudioVolume] = useState<number>(80);
    const [isUploading, setIsUploading] = useState(false); // æ˜¯å¦æœ‰æ–‡ä»¶æ­£åœ¨ä¸Šä¼ 
    const isUploadingRef = useRef(false); // ä½¿ç”¨ ref è§£å†³é—­åŒ…é—®é¢˜
    // è§¦æ‘¸æ‰‹åŠ¿ç›¸å…³çŠ¶æ€
    const [showMask, setShowMask] = useState(false); // æ˜¯å¦æ˜¾ç¤ºé®ç½©å±‚
    const [touchStartX, setTouchStartX] = useState<number>(0); // è§¦æ‘¸èµ·å§‹Xåæ ‡
    const [touchStartY, setTouchStartY] = useState<number>(0); // è§¦æ‘¸èµ·å§‹Yåæ ‡
    const [currentTouchX, setCurrentTouchX] = useState<number>(0); // å½“å‰è§¦æ‘¸Xåæ ‡
    const [currentTouchY, setCurrentTouchY] = useState<number>(0); // å½“å‰è§¦æ‘¸Yåæ ‡
    const [isCanceling, setIsCanceling] = useState(false); // æ˜¯å¦åœ¨å–æ¶ˆåŒºåŸŸ
    const [isMouseDown, setIsMouseDown] = useState(false); // é¼ æ ‡æ˜¯å¦æŒ‰ä¸‹
    // è¯­éŸ³é€šè¯ç›¸å…³çŠ¶æ€
    const [isVoiceCallActive, setIsVoiceCallActive] = useState(false); // æ˜¯å¦å¤„äºè¯­éŸ³é€šè¯æ¨¡å¼
    const isVoiceCallActiveRef = useRef(false); // ä½¿ç”¨ ref è§£å†³é—­åŒ…é—®é¢˜
    const silenceTimerRef = useRef<NodeJS.Timeout | null>(null); // é™é»˜æ£€æµ‹å®šæ—¶å™¨
    const lastContentRef = useRef<string>(''); // ä¸Šæ¬¡è¯†åˆ«çš„å†…å®¹ï¼Œç”¨äºæ£€æµ‹å˜åŒ–
    const {
        messages,
        loading,
        error,
        isAudioPlaying, // ä» useChatSSE è·å–éŸ³é¢‘æ’­æ”¾çŠ¶æ€
        start,
        stop,
        reset,
        stopAudio: stopStreamAudio // åœæ­¢æœåŠ¡å™¨éŸ³é¢‘æµçš„å‡½æ•°
    } = useChatSSE({
        url: `${import.meta.env.VITE_API_BASE_URL}/v3/chat`,
        botId: botIdFromRoute,
    })
    useEffect(() => {
        //è·å–æƒé™
        checkRequirements()
        //è·å–éº¦å…‹é£è®¾å¤‡
        getDevices();
    }, []);

    useEffect(() => {
        if (messageListRef.current) {
            messageListRef.current.scrollTo({
                top: messageListRef.current.scrollHeight,
                behavior: 'smooth'
            });
        }
    }, [messages]);

    // æ‹‰å–å¯ç”¨éŸ³è‰²åˆ—è¡¨
    useEffect(() => {
        const fetchVoices = async () => {
            try {
                const res = await fetch(`${import.meta.env.VITE_API_BASE_URL}/v1/audio/voices`, {
                    method: 'GET',
                    headers: {
                        Authorization: 'Bearer pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE'
                    },
                })
                if (!res.ok) throw new Error(`æ‹‰å–éŸ³è‰²å¤±è´¥: ${res.status}`)
                const data = await res.json()
              let findItem = data?.data?.voice_list?.find(x=>x.voice_id=='7426725529589661723')
                const id = findItem?.voice_id
                if (id) setVoiceId(id)
            } catch (err) {
                console.error('è·å–éŸ³è‰²å¤±è´¥', err)
            }
        }
        fetchVoices()
    }, [])

    // ç»„ä»¶å¸è½½æ—¶å½»åº•æ¸…ç†è¯­éŸ³é“¾è·¯ï¼Œé˜²æ­¢æ®‹ç•™æ’­æ”¾/å½•åˆ¶/è¯·æ±‚
    useEffect(() => () => {
        if (audioRef.current) {
            const src = audioRef.current.src;
            audioRef.current.pause();
            audioRef.current.currentTime = 0;
            audioRef.current = null;
            if (src?.startsWith('blob:')) URL.revokeObjectURL(src);
        }
        if (clientRef.current) {
            try {
                clientRef.current.stop();
            } catch (err) {
                console.error('åœæ­¢è¯­éŸ³å®¢æˆ·ç«¯å¤±è´¥', err);
            }
            clientRef.current = undefined;
        }
        if (speechAbortRef.current) {
            speechAbortRef.current.abort();
            speechAbortRef.current = null;
        }
        // æ¸…ç†è¯­éŸ³é€šè¯çš„å®šæ—¶å™¨
        if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
        }
        pressStartTimeRef.current = null;
        setVoiceStatus('idle');
        recognizeResult.current = {}
        stop?.();
        // isAudioPlaying ç°åœ¨ç”± useChatSSE ç®¡ç†ï¼Œä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®
        stopVoiceActivityDetection();
        setIsVoiceCallActive(false);
        isVoiceCallActiveRef.current = false; // åŒæ­¥æ›´æ–° ref
    }, []);

    // éŸ³é‡å˜åŒ–æ—¶åŒæ­¥åˆ°å½“å‰éŸ³é¢‘
    useEffect(() => {
        if (audioRef.current) {
            audioRef.current.volume = audioVolume / 100
        }
    }, [audioVolume]);

    // åŒæ­¥ fileList state åˆ° refï¼Œè§£å†³è¯­éŸ³é€šè¯ä¸­çš„é—­åŒ…é—®é¢˜
    useEffect(() => {
        fileListRef.current = fileList;
    }, [fileList]);

    // åŒæ­¥ isUploading state åˆ° refï¼Œè§£å†³è¯­éŸ³é€šè¯ä¸­çš„é—­åŒ…é—®é¢˜
    useEffect(() => {
        isUploadingRef.current = isUploading;
    }, [isUploading]);

    useEffect(() => {
        stopAudio()
    }, [currentMode]);
    const playSpeech = async (text: string) => {
        if (!voiceId) return
        if (!text?.trim()) return;
        try {
            // è‹¥å·²æœ‰è¯­éŸ³è¯·æ±‚åœ¨é£è¡Œï¼Œåˆ™å…ˆä¸­æ­¢
            if (speechAbortRef.current) {
                speechAbortRef.current.abort();
            }
            const controller = new AbortController();
            speechAbortRef.current = controller;

            // å…ˆåœæ­¢ä¸Šä¸€æ®µéŸ³é¢‘
            if (audioRef.current) {
                audioRef.current.pause();
                audioRef.current = null;
            }
            // æ³¨æ„ï¼šè¿™æ˜¯ TTS å¤‡ç”¨æ’­æ”¾ï¼Œä¸å½±å“æœåŠ¡å™¨éŸ³é¢‘æµçš„ isAudioPlaying çŠ¶æ€
            const res = await fetch(`${import.meta.env.VITE_API_BASE_URL}/v1/audio/speech`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    Authorization: 'Bearer pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE'
                },
                signal: controller.signal,
                body: JSON.stringify({
                    voice_id: voiceId || '',
                    response_format: 'wav',
                    input: text,
                }),
            })
            if (!res.ok) {
                throw new Error(`TTS è¯·æ±‚å¤±è´¥: ${res.status}`)
            }
            const buffer = await res.arrayBuffer()
            const blob = new Blob([buffer], {type: 'audio/wav'})
            const url = URL.createObjectURL(blob)
            const audio = new Audio(url)
            audio.volume = audioVolume / 100
            audioRef.current = audio
            audio.onended = () => {
                console.log('TTS è¯­éŸ³æ’­æŠ¥å®Œæˆ');
                URL.revokeObjectURL(url)
            }
            audio.onerror = () => {
                console.log('TTS è¯­éŸ³æ’­æŠ¥å‡ºé”™');
                URL.revokeObjectURL(url)
            }
            await audio.play()
            console.log('å¼€å§‹ TTS è¯­éŸ³æ’­æŠ¥')
        } catch (err) {
            if ((err as any)?.name === 'AbortError') return;
            console.error('TTS è¯­éŸ³æ’­æ”¾å¤±è´¥', err)
            message.error('TTS è¯­éŸ³æ’­æ”¾å¤±è´¥')
        } finally {
            speechAbortRef.current = null;
        }
    }

    const stopSpeech = () => {
        if (audioRef.current) {
            audioRef.current.pause()
            audioRef.current.currentTime = 0
            audioRef.current = null
        }
        // TTS æ’­æ”¾åœæ­¢ï¼Œä¸å½±å“æœåŠ¡å™¨éŸ³é¢‘æµçš„ isAudioPlaying çŠ¶æ€
    }

    // å°†æ–‡å­—è½¬æ¢ä¸ºéŸ³é¢‘å¹¶ä¸Šä¼ åˆ°æœåŠ¡å™¨ï¼Œè¿”å›åŒ…å« file_id çš„å¯¹è±¡
    const convertTextToAudioAndUpload = async (text: string) => {
        if (!voiceId) {
            throw new Error('è¯­éŸ³éŸ³è‰²æœªè®¾ç½®');
        }
        if (!text?.trim()) {
            throw new Error('æ–‡æœ¬å†…å®¹ä¸ºç©º');
        }

        try {
            // 1. è°ƒç”¨ TTS API å°†æ–‡å­—è½¬æ¢ä¸ºéŸ³é¢‘
            const ttsRes = await fetch(`${import.meta.env.VITE_API_BASE_URL}/v1/audio/speech`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    Authorization: 'Bearer pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE'
                },
                body: JSON.stringify({
                    voice_id: voiceId,
                    response_format: 'wav',
                    input: text,
                }),
            });

            if (!ttsRes.ok) {
                throw new Error(`TTS è½¬æ¢å¤±è´¥: ${ttsRes.status}`);
            }

            // 2. å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º Blob
            const buffer = await ttsRes.arrayBuffer();
            const audioBlob = new Blob([buffer], { type: 'audio/wav' });

            // 3. åˆ›å»º File å¯¹è±¡ï¼ˆæ¨¡æ‹Ÿç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ï¼‰
            const timestamp = Date.now();
            const audioFile = new File([audioBlob], `voice_${timestamp}.wav`, {
                type: 'audio/wav',
                lastModified: timestamp
            });

            // 4. ä½¿ç”¨ Coze SDK ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
            const uploadResult = await cozeClient.files.upload({
                file: audioFile,
            });

            console.log('ğŸµ éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ æˆåŠŸ:', {
                file_id: uploadResult.id,
                file_name: audioFile.name,
                file_type: audioFile.type,
                file_size: audioFile.size,
                upload_result: uploadResult
            });

            // 5. è¿”å›ä¸Šä¼ ç»“æœï¼Œæ ¼å¼ä¸å›¾ç‰‡ä¸Šä¼ ä¿æŒä¸€è‡´ï¼Œä½†æ ‡è®°ä¸ºéŸ³é¢‘æ–‡ä»¶
            return {
                uid: `audio_${timestamp}`,
                name: audioFile.name,
                status: 'done',
                type: 'audio/wav',
                originFileObj: audioFile,
                response: uploadResult,
                isAudio: true // æ ‡è®°ä¸ºéŸ³é¢‘æ–‡ä»¶ï¼Œç”¨äºåŒºåˆ†å›¾ç‰‡æ–‡ä»¶
            };

        } catch (error) {
            console.error('æ–‡å­—è½¬éŸ³é¢‘ä¸Šä¼ å¤±è´¥:', error);
            throw error;
        }
    }

    // å¯¹è¯ç»“æŸåè‡ªåŠ¨æ’­æŠ¥æœ€åä¸€æ¡ AI å›å¤
    // æ³¨æ„ï¼šç°åœ¨ä½¿ç”¨æœåŠ¡å™¨è¿”å›çš„éŸ³é¢‘æµï¼ˆconversation.audio.deltaï¼‰ï¼Œä¸å†éœ€è¦ TTS æ¥å£
    // useEffect(() => {
    //     if (loading) return
    //     const lastAi = [...messages].reverse().find(m => m.role === 'ai' && m.content?.trim())
    //     if (!lastAi) return
    //     if (spokenMessageId === lastAi.id) return
    //     playSpeech(lastAi.content)
    //     setSpokenMessageId(lastAi.id)
    // }, [messages, loading, voiceId])

    // ç›‘å¬ loading çŠ¶æ€å˜åŒ–ï¼Œåœ¨è¯­éŸ³é€šè¯æ¨¡å¼ä¸‹ AI å›ç­”å®Œæˆåè‡ªåŠ¨é‡æ–°å¼€å§‹å½•éŸ³
    useEffect(() => {
        if (!loading && isVoiceCallActive) {
            // AI å›ç­”å®Œæˆï¼Œå»¶è¿Ÿä¸€å°æ®µæ—¶é—´åé‡æ–°å¼€å§‹å½•éŸ³ï¼ˆç­‰å¾…æ’­æŠ¥å¼€å§‹ï¼‰
            const timer = setTimeout(() => {
                if (clientRef.current && isVoiceCallActiveRef.current) {
                    try {
                        clientRef.current.start();
                        console.log('AIå›ç­”å®Œæˆï¼Œé‡æ–°å¼€å§‹å½•éŸ³ï¼ˆæ’­æŠ¥æœŸé—´ä¹Ÿå¯å½•éŸ³ï¼‰');
                    } catch (err) {
                        console.error('é‡æ–°å¼€å§‹å½•éŸ³å¤±è´¥', err);
                    }
                }
            }, 500); // å»¶è¿Ÿ500msï¼Œç¡®ä¿æ’­æŠ¥å·²ç»å¼€å§‹

            return () => clearTimeout(timer);
        }
    }, [loading, isVoiceCallActive])

    const checkRequirements = async () => {
        // æ£€æŸ¥éº¦å…‹é£æƒé™
        const permission = await WsToolsUtils.checkDevicePermission();
        setHasPermission(permission.audio);

        // æ£€æŸ¥æ˜¯å¦æ”¯æŒAIé™å™ª
        const isDenoiserSupported = WsToolsUtils.checkDenoiserSupport();
        setDenoiserSupported(isDenoiserSupported);
    };
    const getDevices = async () => {
        const devices = await WsToolsUtils.getAudioDevices();
        if (devices.audioInputs.length > 0) {
            setSelectedInputDevice(devices.audioInputs[0].deviceId);
        }
    };

    // ä½¿ç”¨ Web Audio + RMS æ£€æµ‹ç”¨æˆ·æ˜¯å¦åœ¨è¯´è¯ï¼Œæ‰“æ–­æ­£åœ¨æ’­æŠ¥çš„ TTS
    const startVoiceActivityDetection = async () => {
        if (audioContextRef.current || rmsRafRef.current) return;
        try {
            const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
            if (!AudioCtx) {
                console.warn('å½“å‰ç¯å¢ƒä¸æ”¯æŒ Web Audio APIï¼Œæ— æ³•å¯ç”¨ RMS æ£€æµ‹');
                return;
            }
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    deviceId: selectedInputDevice ? { exact: selectedInputDevice } : undefined,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                }
            });
            micStreamRef.current = stream;
            const audioCtx = new AudioCtx();
            audioContextRef.current = audioCtx;
            const source = audioCtx.createMediaStreamSource(stream);
            const analyser = audioCtx.createAnalyser();
            analyser.fftSize = 1024;
            source.connect(analyser);
            analyserRef.current = analyser;
            const buffer = new Uint8Array(analyser.fftSize);
            rmsDataArrayRef.current = buffer;

            const detect = () => {
                if (!analyserRef.current || !rmsDataArrayRef.current) return;
                analyserRef.current.getByteTimeDomainData(rmsDataArrayRef.current);
                let sumSquares = 0;
                for (let i = 0; i < rmsDataArrayRef.current.length; i++) {
                    const v = (rmsDataArrayRef.current[i] - 128) / 128;
                    sumSquares += v * v;
                }
                const rms = Math.sqrt(sumSquares / rmsDataArrayRef.current.length);
                // ç®€å•é—¨é™ï¼Œæ£€æµ‹åˆ°æ˜æ˜¾å‘å£°æ—¶ä¸­æ–­æ’­æŠ¥
                const RMS_THRESHOLD = 0.06;
                if (rms > RMS_THRESHOLD && audioRef.current && !audioRef.current.paused) {
                    console.log('RMS æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯ï¼Œæ‰“æ–­è¯­éŸ³æ’­æŠ¥', rms);
                    stopAudio();
                }
                rmsRafRef.current = requestAnimationFrame(detect);
            };
            rmsRafRef.current = requestAnimationFrame(detect);
        } catch (err) {
            console.error('å¯åŠ¨ RMS è¯­éŸ³æ£€æµ‹å¤±è´¥', err);
        }
    };

    const stopVoiceActivityDetection = () => {
        if (rmsRafRef.current) {
            cancelAnimationFrame(rmsRafRef.current);
            rmsRafRef.current = null;
        }
        if (analyserRef.current) {
            try {
                analyserRef.current.disconnect();
            } catch (err) {
                console.error('æ–­å¼€ analyser å¤±è´¥', err);
            }
            analyserRef.current = null;
        }
        if (audioContextRef.current) {
            audioContextRef.current.close().catch(() => {});
            audioContextRef.current = null;
        }
        if (micStreamRef.current) {
            micStreamRef.current.getTracks().forEach(track => track.stop());
            micStreamRef.current = null;
        }
        rmsDataArrayRef.current = null;
    };

    const initClient = () => {
        if (!hasPermission) {
            throw new Error('éº¦å…‹é£æƒé™æœªæˆäºˆ');
        }
        const client = new WsTranscriptionClient({
            token: 'pat_zkUh7PgT34IDtE2y4VBBgnTZjBc3nZ2yZ9gXIwia6cYxpzfMMiwELEf3sZyjceYE',
            baseWsURL: 'wss://ws.coze.cn',
            allowPersonalAccessTokenInBrowser: true,
            debug: false,
            deviceId: selectedInputDevice,
            // AIé™å™ªé…ç½® - ä»…å½“æµè§ˆå™¨æ”¯æŒå¹¶ä¸”é€‰æ‹©ä½¿ç”¨æ—¶å¼€å¯
            aiDenoisingConfig: denoiserSupported
                ? {
                    mode: AIDenoiserProcessorMode.NSNG, // AIé™å™ªæ¨¡å¼
                    level: AIDenoiserProcessorLevel.SOFT, // èˆ’ç¼“é™å™ª
                    assetsPath:
                        'https://lf3-static.bytednsdoc.com/obj/eden-cn/613eh7lpqvhpeuloz/websocket',
                }
                : undefined,
            // éŸ³é¢‘æ•è·é…ç½®
            audioCaptureConfig: {
                echoCancellation: true,
                noiseSuppression: !denoiserSupported, // å¦‚æœæ”¯æŒAIé™å™ªï¼Œåˆ™ç¦ç”¨æµè§ˆå™¨å†…ç½®é™å™ª
                autoGainControl: true,
            },
        });
        // å¦‚æœä½¿ç”¨AIé™å™ªä½†æµè§ˆå™¨ä¸æ”¯æŒï¼Œåˆ™æç¤ºç”¨æˆ·
        if (!denoiserSupported) {
            message.info('å½“å‰æµè§ˆå™¨ä¸æ”¯æŒAIé™å™ªï¼Œå°†ä½¿ç”¨æµè§ˆå™¨å†…ç½®é™å™ª');
        }
        // ç›‘å¬è½¬å½•ç»“æœæ›´æ–°
        client.on(WebsocketsEventType.TRANSCRIPTIONS_MESSAGE_UPDATE,(event: any) => {
            const userMsg: Message = {
                logid: event.detail.logid,
                id:event.id,
                role: 'user',
                content: event.data.content,
                content_type:'text'
            };
            console.log("ç›‘å¬åˆ°è¯´è¯====>",event.data.content)
            recognizeResult.current = userMsg;

            // å¦‚æœå¤„äºè¯­éŸ³é€šè¯æ¨¡å¼ï¼Œè§¦å‘é™é»˜æ£€æµ‹
            if (isVoiceCallActiveRef.current) {
                handleVoiceCallContentUpdate(event.data.content);
            }
        });


        // ç›‘å¬é”™è¯¯äº‹ä»¶
        client.on(WebsocketsEventType.ERROR, (error: unknown) => {
            console.error(error);
            // message.error((error as CommonErrorEvent).data.msg);
        });
        clientRef.current = client;
        // å¯åŠ¨ RMS è¯­éŸ³æ£€æµ‹ï¼Œç‹¬ç«‹äºè½¬å†™ç»“æœ
        startVoiceActivityDetection();
    }
    const switchMode = (mode: InputMode) => {
        if (mode === 'voice' && !clientRef.current) {
            try {
                initClient();
            } catch (error) {
                console.error(error);
                message.error((error as Error).message || 'è¯­éŸ³åˆå§‹åŒ–å¤±è´¥');
                return;
            }
        }
        setCurrentMode(mode);
    };


    // å¼€å§‹è¯­éŸ³é€šè¯
    const startVoiceCall = () => {
        stopAudio();

        // å¦‚æœæœ‰æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ï¼Œä¸å…è®¸å¼€å§‹é€šè¯
        if (isUploading) {
            message.warning('æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ä¸­ï¼Œè¯·ç¨å€™...');
            return;
        }

        // æ­£åœ¨ç”Ÿæˆå›ç­”æ—¶ä¸å…è®¸å¼€å§‹é€šè¯
        if (loading) {
            message.warning('AIæ­£åœ¨å›ç­”ä¸­ï¼Œè¯·ç¨å€™...');
            return;
        }

        // åˆå§‹åŒ–è¯­éŸ³å®¢æˆ·ç«¯
        try {
            if (!clientRef.current) {
                initClient();
            }
        } catch (error) {
            console.error(error);
            message.error((error as Error).message || 'è¯­éŸ³åˆå§‹åŒ–å¤±è´¥');
            return;
        }

        // æ¸…ç©ºä¸Šæ¬¡çš„è¯†åˆ«å†…å®¹
        lastContentRef.current = '';
        recognizeResult.current = {} as Message;

        // è®¾ç½®é€šè¯çŠ¶æ€
        setIsVoiceCallActive(true);
        isVoiceCallActiveRef.current = true; // åŒæ­¥æ›´æ–° ref

        // å¼€å§‹å½•éŸ³ï¼ˆè¯­éŸ³é€šè¯æ¨¡å¼ä¸æ”¹å˜ voiceStatusï¼‰
        clientRef.current.start();

        message.success('è¯­éŸ³é€šè¯å·²å¼€å¯ï¼Œè¯·å¼€å§‹è¯´è¯');
    };

    // åœæ­¢è¯­éŸ³é€šè¯
    const stopVoiceCall = () => {
        stopAudio()
        // æ¸…é™¤é™é»˜å®šæ—¶å™¨
        if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
        }

        // åœæ­¢å½•éŸ³
        if (clientRef.current) {
            try {
                clientRef.current.stop();
            } catch (err) {
                console.error('åœæ­¢å½•éŸ³å¤±è´¥', err);
            }
        }

        // é‡ç½®çŠ¶æ€ï¼ˆä¸æ”¹å˜ voiceStatus å’Œ currentModeï¼‰
        setIsVoiceCallActive(false);
        isVoiceCallActiveRef.current = false; // åŒæ­¥æ›´æ–° ref
        lastContentRef.current = '';
        recognizeResult.current = {} as Message;

        message.info('è¯­éŸ³é€šè¯å·²ç»“æŸ');
    };

    // å¤„ç†è¯­éŸ³é€šè¯ä¸­çš„å†…å®¹æ›´æ–°ï¼Œè§¦å‘é™é»˜æ£€æµ‹
    const handleVoiceCallContentUpdate = (content: string) => {
        // å¦‚æœå›¾ç‰‡æ­£åœ¨ä¸Šä¼ ï¼Œä¸è§¦å‘é™é»˜æ£€æµ‹
        if (isUploadingRef.current) {
            console.log('å›¾ç‰‡æ­£åœ¨ä¸Šä¼ ä¸­ï¼Œæš‚ä¸è§¦å‘è‡ªåŠ¨å‘é€');
            return;
        }

        // æ¸…é™¤ä¹‹å‰çš„å®šæ—¶å™¨
        if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
            console.log("é‡ç½®å®šæ—¶å™¨")
        }
        // å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œè¯´æ˜ç”¨æˆ·è¿˜åœ¨è¯´è¯
        if (content && content !== lastContentRef.current) {
            lastContentRef.current = content;

            // è®¾ç½®æ–°çš„é™é»˜æ£€æµ‹å®šæ—¶å™¨ï¼ˆä»å…¨å±€é…ç½®è¯»å–æ—¶é•¿ï¼‰
            silenceTimerRef.current = setTimeout(() => {
                // Nç§’åå¦‚æœæ²¡æœ‰æ–°çš„å†…å®¹æ›´æ–°ï¼Œåˆ™è‡ªåŠ¨å‘é€
                handleAutoSendInVoiceCall();

            }, getVoiceCallSilenceTimeout());
        }
    };

    // è¯­éŸ³é€šè¯æ¨¡å¼ä¸‹çš„è‡ªåŠ¨å‘é€
    const handleAutoSendInVoiceCall = async () => {
        console.log("è§¦å‘å‘é€")
        if (!isVoiceCallActiveRef.current) return;

        // æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
        const content = recognizeResult.current?.content?.trim();
        if (!content) {
            // æ²¡æœ‰å†…å®¹ï¼Œé‡æ–°å¼€å§‹å½•éŸ³
            lastContentRef.current = '';
            return;
        }

        // åœæ­¢å½“å‰å½•éŸ³
        if (clientRef.current) {
            try {
              clientRef.current.stop();
                clientRef.current.start();
            } catch (err) {
                console.error('åœæ­¢å½•éŸ³å¤±è´¥', err);
            }
        }

        // å‘é€æ¶ˆæ¯ï¼ˆä½¿ç”¨ ref è·å–æœ€æ–°çš„æ–‡ä»¶åˆ—è¡¨ï¼‰
        const messageToSend = {
            ...recognizeResult.current,
            imageUrls: fileListRef.current.length > 0 ? fileListRef.current : undefined
        };
        console.log(messageToSend, fileListRef.current)
        try {
            await start(messageToSend);
            setFileList([]);
            recognizeResult.current = {} as Message;
            lastContentRef.current = '';
            console.log(" lastContentRef.current", lastContentRef.current)

            // ç­‰å¾… AI å›ç­”å®Œæˆåï¼Œè‡ªåŠ¨é‡æ–°å¼€å§‹å½•éŸ³
            // è¿™ä¸ªé€»è¾‘ä¼šåœ¨ loading çŠ¶æ€å˜åŒ–æ—¶å¤„ç†
        } catch (error) {
            console.error('è‡ªåŠ¨å‘é€å¤±è´¥:', error);
            message.error('å‘é€å¤±è´¥');
        }
    };

    const startRecording = () => {
        stopAudio()
        // å¦‚æœå¤„äºè¯­éŸ³é€šè¯æ¨¡å¼ï¼Œä¸å…è®¸æŒ‰ä½è¯´è¯
        if (isVoiceCallActive) {
            message.warning('è¯­éŸ³é€šè¯è¿›è¡Œä¸­ï¼Œè¯·å…ˆç»“æŸé€šè¯');
            return;
        }

        // å¦‚æœæœ‰æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ï¼Œä¸å…è®¸å½•éŸ³
        if (isUploading) {
            message.warning('æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ä¸­ï¼Œè¯·ç¨å€™...');
            return;
        }
        // æ­£åœ¨ç”Ÿæˆå›ç­”æ—¶ä¸å…è®¸å†æ¬¡å½•éŸ³
        if (loading) return;

        // è‡ªåŠ¨åˆ‡æ¢åˆ°è¯­éŸ³æ¨¡å¼å¹¶åˆå§‹åŒ–å®¢æˆ·ç«¯
        if (currentMode !== 'voice') {
            try {
                if (!clientRef.current) {
                    initClient();
                }
                setCurrentMode('voice');
            } catch (error) {
                console.error(error);
                message.error((error as Error).message || 'è¯­éŸ³åˆå§‹åŒ–å¤±è´¥');
                return;
            }
        }

        pressStartTimeRef.current = Date.now();
        clientRef.current.start()
        setVoiceStatus('recording');
    };

    const stopRecording = async () => {
        if (currentMode !== 'voice' || voiceStatus !== 'recording'){

            return
        };

        // ç«‹å³é‡ç½®UIçŠ¶æ€ï¼Œè®©ç”¨æˆ·çœ‹åˆ°å·²åœæ­¢å½•éŸ³
        setVoiceStatus('idle');

        // å¦‚æœæœ‰æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ï¼Œä¸å…è®¸å‘é€
        if (isUploading) {
            message.warning('æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ä¸­ï¼Œè¯·ç¨å€™...');
            return;
        }
        const pressDuration = pressStartTimeRef.current ? Date.now() - pressStartTimeRef.current : 0;
        pressStartTimeRef.current = null;

        if(!recognizeResult?.current?.content&&!fileList.length){
            clientRef?.current?.stop()
            return;
        }
        if (pressDuration < 500) {
            clientRef?.current?.stop()
            message.warning('æ—¶é—´è¿‡çŸ­');
            return;
        }
        try {
            setTimeout(()=>{
                clientRef?.current?.stop()
                const messageWithImages = {
                    ...(recognizeResult?.current ||{}),
                    imageUrls: fileList.length > 0 ? fileList : undefined
                };
                start(messageWithImages)
                // å‘é€åæ¸…ç©ºæ–‡ä»¶åˆ—è¡¨å’Œè¯†åˆ«ç»“æœ
                setFileList([]);
                recognizeResult.current = {}
            },1000)
            // å°†ä¸Šä¼ çš„å›¾ç‰‡é™„åŠ åˆ°è¯­éŸ³è¯†åˆ«ç»“æœä¸­

    } catch (error) {
            console.error('è°ƒç”¨chatæ¥å£å¤±è´¥:', error);
            message.error('è¯·æ±‚å¤±è´¥');
            // å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿè¦æ¸…ç©º
            recognizeResult.current = {}
        }
    };

    // å®‰å…¨åœæ­¢å½•éŸ³ï¼šé¿å…åœ¨å¤šä¸ªåˆ†æ”¯é‡Œé‡å¤ try/catch
    const safeStopTranscription = () => {
        if (!clientRef.current) return;
        try {
            clientRef.current.stop();
        } catch (err) {
            console.error('åœæ­¢å½•éŸ³å¤±è´¥', err);
        }
    };

    // ç»Ÿä¸€ç»„è£…â€œè¯­éŸ³è¯†åˆ«ç»“æœ + å›¾ç‰‡â€æ¶ˆæ¯ä½“ï¼ˆä¿æŒç°æœ‰å­—æ®µç»“æ„ä¸å˜ï¼‰
    const buildMessageWithImages = (baseMessage: any, images: UploadFile[]) => {
        return {
            ...(baseMessage || {}),
            imageUrls: images.length > 0 ? images : undefined
        };
    };

    // ç»Ÿä¸€å¤„ç†ï¼šæŒ‰ä½è¯´è¯æ¾æ‰‹åçš„å‘é€/å–æ¶ˆé€»è¾‘ï¼ˆè§¦æ‘¸/é¼ æ ‡å…±ç”¨ï¼‰
    const finalizePressToTalk = (options: {
        cancel: boolean;
        pressDuration: number;
        fileListSnapshot: UploadFile[];
    }) => {
        const { cancel, pressDuration, fileListSnapshot } = options;

        // å–æ¶ˆå‘é€
        if (cancel) {
            safeStopTranscription();
            recognizeResult.current = {} as Message;
            message.info('å·²å–æ¶ˆå‘é€');
            setIsCanceling(false);
            return;
        }

        // æ— è¯­éŸ³å†…å®¹ä¸”æ— å›¾ç‰‡ï¼šä»…åœæ­¢å½•éŸ³ï¼Œä¸è§¦å‘å‘é€
        if (!recognizeResult?.current?.content && fileListSnapshot.length === 0) {
            safeStopTranscription();
            return;
        }

        // å½•éŸ³æ—¶é—´è¿‡çŸ­
        if (pressDuration < 500) {
            safeStopTranscription();
            message.warning('æ—¶é—´è¿‡çŸ­');
            return;
        }

        // æ–‡ä»¶ä¸Šä¼ ä¸­ä¸å…è®¸å‘é€
        if (isUploading) {
            message.warning('æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ä¸­ï¼Œè¯·ç¨å€™...');
            return;
        }

        // å»¶è¿Ÿå‘é€ï¼šä¿ç•™åŸé€»è¾‘ï¼Œç»™è¯­éŸ³è¯†åˆ«ä¸€ä¸ªæ”¶å°¾æ—¶é—´
        setTimeout(() => {
            safeStopTranscription();
            const messageWithImages = buildMessageWithImages(
                recognizeResult?.current || {},
                fileListSnapshot
            );
            start(messageWithImages);
            // å‘é€åæ¸…ç©ºæ–‡ä»¶åˆ—è¡¨å’Œè¯†åˆ«ç»“æœ
            setFileList([]);
            recognizeResult.current = {} as Message;
        }, 1000);
    };

    // è§¦æ‘¸æ‰‹åŠ¿å¤„ç†å‡½æ•°
    const handleVoiceTouchStart = (e: React.TouchEvent) => {
        e.preventDefault();
        const touch = e.touches[0];
        setTouchStartX(touch.clientX);
        setTouchStartY(touch.clientY);
        setCurrentTouchX(touch.clientX);
        setCurrentTouchY(touch.clientY);
        setShowMask(true);
        setIsCanceling(false);
        startRecording();
    };

    const handleVoiceTouchMove = (e: React.TouchEvent) => {
        e.preventDefault();
        const touch = e.touches[0];
        setCurrentTouchX(touch.clientX);
        setCurrentTouchY(touch.clientY);

        // è®¡ç®—æ»‘åŠ¨è·ç¦»ï¼Œå‘å·¦æ»‘åŠ¨ä¸ºè´Ÿå€¼
        const distance = touchStartX - touch.clientX;
        // å¦‚æœå‘å·¦æ»‘åŠ¨è¶…è¿‡100pxï¼Œåˆ™è¿›å…¥å–æ¶ˆåŒºåŸŸ
        const CANCEL_THRESHOLD = 100;
        setIsCanceling(distance > CANCEL_THRESHOLD);
    };

    const handleVoiceTouchEnd = (e: React.TouchEvent) => {
        e.preventDefault();
        setShowMask(false);
        setIsMouseDown(false);

        // ç«‹å³é‡ç½®å½•éŸ³çŠ¶æ€åˆ° idleï¼Œè®©UIé©¬ä¸Šæ¢å¤
        setVoiceStatus('idle');

        // å¦‚æœåœ¨å–æ¶ˆåŒºåŸŸï¼Œåˆ™å–æ¶ˆå‘é€ï¼›å¦åˆ™è§¦å‘å‘é€
        if (isCanceling) {
            finalizePressToTalk({
                cancel: true,
                pressDuration: 0,
                fileListSnapshot: []
            });
        } else {
            const pressDuration = pressStartTimeRef.current
                ? Date.now() - pressStartTimeRef.current
                : 0;
            pressStartTimeRef.current = null;
            const fileListSnapshot = [...fileList];
            finalizePressToTalk({
                cancel: false,
                pressDuration,
                fileListSnapshot
            });
        }

        setTouchStartX(0);
        setTouchStartY(0);
        setCurrentTouchX(0);
        setCurrentTouchY(0);
    };

    // é¼ æ ‡æ‰‹åŠ¿å¤„ç†å‡½æ•°
    const handleVoiceMouseDown = (e: React.MouseEvent) => {
        e.preventDefault();
        setIsMouseDown(true);
        setTouchStartX(e.clientX);
        setTouchStartY(e.clientY);
        setCurrentTouchX(e.clientX);
        setCurrentTouchY(e.clientY);
        setShowMask(true);
        setIsCanceling(false);
        startRecording();

        // ä¿å­˜èµ·å§‹ä½ç½®ï¼Œç”¨äºè®¡ç®—è·ç¦»
        const startX = e.clientX;
        let currentCanceling = false;

        // åœ¨ document ä¸Šæ·»åŠ äº‹ä»¶ç›‘å¬ï¼Œè¿™æ ·å³ä½¿é¼ æ ‡ç§»å‡ºå…ƒç´ ä¹Ÿèƒ½ç›‘å¬åˆ°
        const handleDocumentMouseMove = (e: MouseEvent) => {
            e.preventDefault();
            setCurrentTouchX(e.clientX);
            setCurrentTouchY(e.clientY);

            // è®¡ç®—æ»‘åŠ¨è·ç¦»ï¼Œå‘å·¦æ»‘åŠ¨ä¸ºè´Ÿå€¼
            const dist = startX - e.clientX;
            // å¦‚æœå‘å·¦æ»‘åŠ¨è¶…è¿‡100pxï¼Œåˆ™è¿›å…¥å–æ¶ˆåŒºåŸŸ
            const CANCEL_THRESHOLD = 100;
            currentCanceling = dist > CANCEL_THRESHOLD;
            setIsCanceling(currentCanceling);
        };

        const handleDocumentMouseUp = (e: MouseEvent) => {
            e.preventDefault();
            setIsMouseDown(false);
            setShowMask(false);

            // ç§»é™¤ document äº‹ä»¶ç›‘å¬
            document.removeEventListener('mousemove', handleDocumentMouseMove);
            document.removeEventListener('mouseup', handleDocumentMouseUp);

            // ç«‹å³é‡ç½®å½•éŸ³çŠ¶æ€åˆ° idleï¼Œè®©UIé©¬ä¸Šæ¢å¤
            setVoiceStatus('idle');

            // å¦‚æœåœ¨å–æ¶ˆåŒºåŸŸï¼Œåˆ™å–æ¶ˆå‘é€ï¼›å¦åˆ™è§¦å‘å‘é€
            if (currentCanceling) {
                finalizePressToTalk({
                    cancel: true,
                    pressDuration: 0,
                    fileListSnapshot: []
                });
            } else {
                const pressDuration = pressStartTimeRef.current
                    ? Date.now() - pressStartTimeRef.current
                    : 0;
                pressStartTimeRef.current = null;
                const fileListSnapshot = [...fileList];
                finalizePressToTalk({
                    cancel: false,
                    pressDuration,
                    fileListSnapshot
                });
            }

            setTouchStartX(0);
            setTouchStartY(0);
            setCurrentTouchX(0);
            setCurrentTouchY(0);
        };

        // æ·»åŠ  document äº‹ä»¶ç›‘å¬
        document.addEventListener('mousemove', handleDocumentMouseMove);
        document.addEventListener('mouseup', handleDocumentMouseUp);
    };

    const openCamera = () => {
        stopAudio()
        setCameraModalVisible(true);
    };

    const closeCamera = () => {
        setCameraModalVisible(false);
    };

    // æ‹æ‘„ç»“æœï¼šå…ˆå±•ç¤ºåœ¨åˆ—è¡¨ï¼Œå†è°ƒç”¨ä¸Šä¼ 
    const handleCapturedImage = async (url: string) => {
        try {
            // URL â†’ Blob â†’ File
            const res = await fetch(url);
            const blob = await res.blob();
            const fileName = `capture_${Date.now()}.jpg`;
            const file = new File([blob], fileName, { type: blob.type || 'image/jpeg' });

            const uploadFile: UploadFile = {
                uid: `camera_${Date.now()}`,
                name: fileName,
                originFileObj: file,
                type: file.type,
                url,
                status: 'uploading',
            };

            // å…ˆå†™å…¥åˆ—è¡¨ä»¥å±•ç¤ºç¼©ç•¥å›¾/è¿›åº¦
            setFileList(prev => [...prev, uploadFile]);

            await uploadFileWithFetch(uploadFile);
        } catch (err) {
            console.error('ä¸Šä¼ æ‹æ‘„å›¾ç‰‡å¤±è´¥', err);
            message.error('æ‹æ‘„å›¾ç‰‡ä¸Šä¼ å¤±è´¥');
        } finally {
            setCurrentMode('text');
        }
    };
    // ç§»é™¤æ–‡ä»¶
    const handleRemoveFile = (file: UploadFile) => {
        const newFileList = fileList.filter(item => item.uid !== file.uid);
        setFileList(newFileList);
        message.info(`å·²ç§»é™¤ ${file.name}`);
    };

    // åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡
    const isImageFile = (file: UploadFile) => {
        return file.type?.startsWith('image/');
    };

    // è·å–æ–‡ä»¶é¢„è§ˆURL
    const getFilePreviewUrl = (file: UploadFile) => {
        if (file.originFileObj) {
            return URL.createObjectURL(file.originFileObj);
        }
        return file.url || '';
    };
    // ä½¿ç”¨æ‰£å­ SDK ä¸Šä¼ æ–‡ä»¶
    const uploadFileWithFetch = async (file: UploadFile) => {
        try {
            // æ ‡è®°å¼€å§‹ä¸Šä¼ 
            setIsUploading(true);

            // æ›´æ–°æ–‡ä»¶çŠ¶æ€ä¸ºä¸Šä¼ ä¸­
            setFileList(prev => prev.map(f =>
                f.uid === file.uid ? { ...f, status: 'uploading' } : f
            ));

            // ä½¿ç”¨ Coze SDK ä¸Šä¼ æ–‡ä»¶
            const result = await cozeClient.files.upload({
                file: file.originFileObj as File,
            });


            // æ›´æ–°æ–‡ä»¶çŠ¶æ€ä¸ºæˆåŠŸ
            setFileList(prev => prev.map(f =>
                f.uid === file.uid ? { ...f, status: 'done', response: result } : f
            ));
            message.success(`${file.name} æ–‡ä»¶ä¸Šä¼ æˆåŠŸ`);

        } catch (error) {
            console.error('ä¸Šä¼ å¤±è´¥:', error);
            // ä¸Šä¼ å¤±è´¥æ—¶ä»åˆ—è¡¨ä¸­ç§»é™¤è¯¥æ–‡ä»¶
            setFileList(prev => prev.filter(f => f.uid !== file.uid));
            message.error(`${file.name} æ–‡ä»¶ä¸Šä¼ å¤±è´¥: ${(error as Error).message || 'æœªçŸ¥é”™è¯¯'}`);
        } finally {
            // æ ‡è®°ä¸Šä¼ ç»“æŸ
            setIsUploading(false);

            // å›¾ç‰‡ä¸Šä¼ å®Œæˆåï¼Œå¦‚æœå¤„äºè¯­éŸ³é€šè¯æ¨¡å¼ä¸”æœ‰å¾…å‘é€çš„å†…å®¹ï¼Œé‡æ–°è§¦å‘é™é»˜æ£€æµ‹
            if (isVoiceCallActiveRef.current && lastContentRef.current) {
                console.log('å›¾ç‰‡ä¸Šä¼ å®Œæˆï¼Œé‡æ–°è§¦å‘é™é»˜æ£€æµ‹');
                handleVoiceCallContentUpdate(lastContentRef.current);
            }
        }
    };

    const handleFileUpload: UploadProps['onChange'] = (info) => {
        console.log('æ–‡ä»¶å˜åŒ–:', info.fileList);
    };
    const uploadProps: UploadProps = {
        fileList,
        onChange: handleFileUpload,
        beforeUpload: (file) => {
            // éªŒè¯æ–‡ä»¶ç±»å‹
            const isValidType = [
                'application/pdf',
                'image/jpeg',
                'image/jpg',
                'image/png',
                'application/msword',
                'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
            ].includes(file.type);
            if (!isValidType) {
                message.error('åªæ”¯æŒä¸Šä¼  PDFã€å›¾ç‰‡ã€Word æ–‡ä»¶!');
                return Upload.LIST_IGNORE;
            }

            // éªŒè¯æ–‡ä»¶å¤§å°
            const isLt10M = file.size / 1024 / 1024 < 10;
            if (!isLt10M) {
                message.error('æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡ 10MB!');
                return Upload.LIST_IGNORE;
            }

            // æ·»åŠ åˆ°æ–‡ä»¶åˆ—è¡¨
            const newFile: UploadFile = {
                uid: file.uid,
                name: file.name,
                status: 'uploading',
                originFileObj: file,
                type: file.type,
            };
            setFileList(prev => [...prev, newFile]);

            // ä½¿ç”¨ fetch æ‰‹åŠ¨ä¸Šä¼ 
            uploadFileWithFetch(newFile);

            // è¿”å› false é˜»æ­¢ antd çš„è‡ªåŠ¨ä¸Šä¼ 
            return false;
        },
        showUploadList: false,
        maxCount: 3,
        multiple: true,
    };

    const stopAudio =()=>{
        console.log("åœæ­¢ TTS æ’­æŠ¥")
        if (audioRef.current) {
            audioRef.current.pause();
            audioRef.current.currentTime = 0;
            audioRef.current = null;
        }
        // æ³¨æ„ï¼šTTS æ’­æ”¾åœæ­¢ï¼Œä¸å½±å“æœåŠ¡å™¨éŸ³é¢‘æµçš„ isAudioPlaying çŠ¶æ€
        // å¦‚æœéœ€è¦åœæ­¢æœåŠ¡å™¨éŸ³é¢‘æµï¼Œè¯·è°ƒç”¨ stopStreamAudio()
        // ç»ˆæ­¢æ­£åœ¨è¿›è¡Œçš„ TTS è¯·æ±‚
        if (speechAbortRef.current) {
            speechAbortRef.current.abort();
            speechAbortRef.current = null;
        }
    }

    // æ–°å»ºå¯¹è¯
    const handleNewConversation = () => {
        // åœæ­¢ TTS éŸ³é¢‘æ’­æ”¾
        stopAudio();
        // åœæ­¢æœåŠ¡å™¨éŸ³é¢‘æµæ’­æ”¾
        stopStreamAudio();
        // åœæ­¢è¯­éŸ³é€šè¯
        if (isVoiceCallActive) {
            stopVoiceCall();
        }
        // åœæ­¢è¯­éŸ³è¯†åˆ«
        if (clientRef.current && voiceStatus === 'recording') {
            clientRef.current.stop();
            setVoiceStatus('idle');
        }
        // æ¸…ç©ºæ–‡ä»¶åˆ—è¡¨
        setFileList([]);
        // æ¸…ç©ºæ–‡æœ¬è¾“å…¥
        setTextInput('');
        // æ¸…ç©ºè¯†åˆ«ç»“æœ
        recognizeResult.current = {} as Message;
        // é‡ç½®å·²æ’­æŠ¥æ¶ˆæ¯ID
        setSpokenMessageId(null);
        // æ¸…ç©ºå¯¹è¯å†å²
        reset();
        // è‡ªåŠ¨å‘é€"ä½ å¥½"
        handleSendText('ä½ å¥½');
    };

    const handleSendText = async (contentOverride?: string) => {

        // å¦‚æœæœ‰æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ï¼Œä¸å…è®¸å‘é€
        if (isUploading) {
            message.warning('æ–‡ä»¶æ­£åœ¨ä¸Šä¼ ä¸­ï¼Œè¯·ç¨å€™...');
            return;
        }

        const content = (contentOverride || textInput).trim();
        // loading ä¸­æˆ–æ— è¾“å…¥æ—¶ä¸è§¦å‘
        if(!fileList.length){
            if (loading || !content ) return;
        }
        stopAudio()

        try {
            // 1. å°†æ–‡å­—è½¬æ¢ä¸ºéŸ³é¢‘å¹¶ä¸Šä¼ 
            let audioFileObj = null;
            if (content && voiceId) {
                try {
                    message.loading('æ­£åœ¨ç”Ÿæˆè¯­éŸ³...', 0);
                    audioFileObj = await convertTextToAudioAndUpload(content);
                    message.destroy(); // å…³é—­ loading æç¤º
                    message.success('è¯­éŸ³ç”ŸæˆæˆåŠŸ');
                } catch (error) {
                    message.destroy();
                    console.error('è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œå°†ä»…å‘é€æ–‡å­—:', error);
                    message.warning('è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œä»…å‘é€æ–‡å­—');
                }
            }

            // 2. æ„å»ºå®Œæ•´çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆå›¾ç‰‡ + éŸ³é¢‘ï¼‰
            const allFiles = [...fileList];
            if (audioFileObj) {
                allFiles.push(audioFileObj);
            }

            // 3. æ„å»ºç”¨æˆ·æ¶ˆæ¯å¯¹è±¡
            const userMsg = {
                id: Date.now(),
                role: 'user',
                content,
                content_type: 'text',
                imageUrls: allFiles.length > 0 ? allFiles : undefined
            };

            setTextInput('');
            // æ¸…ç©ºæ–‡ä»¶åˆ—è¡¨
            setFileList([]);

            // 4. å‘é€æ¶ˆæ¯åˆ° /v3/chat
            await start(userMsg);
        } catch (error) {
            console.error('è°ƒç”¨chatæ¥å£å¤±è´¥:', error);
            message.error('è¯·æ±‚å¤±è´¥');
        }
    };


    // å¤„ç†ä»é¦–é¡µé¢„è®¾é—®é¢˜è·³è½¬æ—¶è‡ªåŠ¨æé—®
    useEffect(() => {
        const state = location.state as { initialQuestion?: string } | undefined;
        const rawQuestion = state?.initialQuestion;

        // ä¸¥æ ¼æ£€æŸ¥ï¼šç¡®ä¿ initialQuestion æ˜¯å­—ç¬¦ä¸²ç±»å‹
        if (typeof rawQuestion !== 'string') {
            if (rawQuestion !== undefined) {
                console.warn('initialQuestion ä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå·²å¿½ç•¥', rawQuestion);
            }
            return;
        }

        const question = rawQuestion.trim();
        if (!question) return;
        if (initialQuestionRef.current === question) return;

        initialQuestionRef.current = question;
        setCurrentMode('text');
        setTextInput(question);
        handleSendText(question);
    }, [location.state]);

    // ç»Ÿä¸€æ¸²æŸ“è¾“å…¥åŒºåŸŸï¼šä»…ä¿ç•™æ–‡æœ¬è¾“å…¥æ¨¡å¼
    const renderInputArea = () => {
        const sendDisabled = loading || isUploading;

        // è¯­éŸ³é€šè¯æ¨¡å¼ï¼šä»…å±•ç¤ºçŠ¶æ€æç¤ºï¼Œä¸å±•ç¤ºè¾“å…¥æŒ‰é’®
        if (isVoiceCallActive) {
            return (
                <div className={styles.textInputWrapper}>
                    <div className={styles.textInputContainer}>
                        <div className={`${styles.voicePrompt} ${styles.calling}`}>
                            <Phone className={styles.voiceIcon} size={20} />
                            <span className={styles.voiceText}>
                                {loading ? 'AIæ­£åœ¨å›ç­”...' : 'è¯­éŸ³é€šè¯ä¸­...'}
                            </span>
                        </div>
                    </div>
                </div>
            );
        }

        // å½•éŸ³ä¸­ï¼šæ˜¾ç¤ºè¯­éŸ³æ¨¡å¼æç¤º
        if (voiceStatus === 'recording'&&false) {
            return (
                <div className={styles.textInputWrapper}>
                    <div className={styles.textInputContainer}>
                        <div className={`${styles.voicePrompt} ${styles.recording}`}>
                            <Mic className={styles.voiceIcon} size={20} />
                            <span className={styles.voiceText}>å½“å‰å¤„äºè¯­éŸ³æ¨¡å¼</span>
                        </div>
                    </div>
                </div>
            );
        }

        // æ–‡æœ¬è¾“å…¥æ¨¡å¼
        return (
            <div className={styles.textInputWrapper}>
                <div className={styles.textInputContainer}>
                    <textarea
                        value={textInput}
                        onChange={(e) => setTextInput(e.target.value)}
                        onKeyDown={(e) => {
                            if (e.key === 'Enter' && !e.shiftKey) {
                                e.preventDefault();
                                handleSendText();
                            }
                        }}
                        placeholder="è¯·è¾“å…¥æŒ‡ä»¤..."
                        className={styles.textInput}
                        disabled={loading || isUploading}
                        rows={1}
                    />

                    <button
                        onClick={() => handleSendText()}
                        className={styles.sendButton}
                        disabled={sendDisabled}
                    >
                        <Send size={18} />
                    </button>
                </div>
            </div>
        );
    };

    const getToolbarButtonClasses = (mode: InputMode) => {
        const classNames = [styles.toolbarButton];
        if (currentMode === mode) {
            classNames.push(styles.active, styles[mode]);
        }
        if (mode === 'voice' && voiceStatus === 'recording') {
            classNames.push(styles.recording);
        }
        return classNames.join(' ');
    };
    return (
        <>
            {/* å…¨å±è¯­éŸ³é®ç½©å±‚ */}
            {showMask && (
                <div className={styles.voiceMask}>
                    <div className={styles.maskContent}>
                        <div className={styles.maskIcon}>
                            <Mic size={60} />
                        </div>
                        <div className={styles.maskText}>
                            {isCanceling ? 'æ¾å¼€ï¼Œå–æ¶ˆå‘é€' : 'å·¦æ»‘å–æ¶ˆ'}
                        </div>
                        <div className={styles.maskHint}>
                            {isCanceling ? '' : 'æ¾å¼€ï¼Œå‘é€æ¶ˆæ¯'}
                        </div>
                    </div>
                </div>
            )}

            <div className={styles.container}>
                <div className={styles.phone}>
                    {/* Corner Decorations */}
                    <div className={styles.cornerTL}></div>
                    <div className={styles.cornerTR}></div>
                    <div className={styles.cornerBL}></div>
                    <div className={styles.cornerBR}></div>

                    <div className={styles.contentWrapper}>
                        <div className={styles.topNav}>
                            <h1>{pageTitle}</h1>
                            <div className={styles.topNavStatus}>åœ¨çº¿</div>
                        </div>

                        <div className={styles.mainContent}>
                            <div className={styles.chatArea}>
                                <div className={styles.modeInfo}>
                                    <p>
                                        {isVoiceCallActive && '>>> è¯­éŸ³é€šè¯è¿›è¡Œä¸­...'}
                                        {!isVoiceCallActive && currentMode === 'voice' && '>>> è¯­éŸ³è¾“å…¥æ¨¡å¼å·²æ¿€æ´»'}
                                        {!isVoiceCallActive && currentMode === 'text' && '>>> æ–‡å­—æŒ‡ä»¤è¾“å…¥å°±ç»ª'}
                                        {!isVoiceCallActive && currentMode === 'file' && '>>> æ–‡ä»¶è§£ææ¨¡å—åŠ è½½å®Œæ¯•'}
                                        {!isVoiceCallActive && currentMode === 'camera' && '>>> è§†è§‰ä¼ æ„Ÿå™¨å·²è¿æ¥'}
                                    </p>
                                </div>

                                <div className={styles.messageList} ref={messageListRef}>
                                    <div className={styles.messageListInner}>
                                        {messages.map((message, index) => {
                                            const isLast = index === messages.length - 1;
                                            const hasContent = !!message.content?.trim();
                                            const showLoadingBubble = loading && isLast && message.role === 'ai' && !hasContent;
                                            return (
                                                <div key={message.id} className={`${styles.messageRow} ${styles[message.role]} ${showLoadingBubble ? styles.loadingMessage : ''}`}>
                                                    {message.role !== 'system' && (
                                                        <div className={`${styles.avatar} ${styles[message.role]}`}>
                                                            {message.role === 'user' ? <User size={20}/> : <Bot size={20}/>}
                                                        </div>
                                                    )}
                                                    <div className={`${styles.messageContentWrapper} ${styles[message.role]}`}>
                                                        {message.role === 'system' ? (
                                                            <div className={`${styles.messageBubble} ${styles.system}`}>
                                                                <p>ç³»ç»Ÿæ¶ˆæ¯: {message.content}</p>
                                                            </div>
                                                        ) : (
                                                            <div className={`${styles.messageBubble} ${styles[message.role]} ${showLoadingBubble ? styles.loadingBubble : ''}`}>
                                                                {showLoadingBubble && <div className={styles.bubbleSpinner}></div>}
                                                                {message.imageUrls && message.imageUrls.length > 0 && (
                                                                    <div className={styles.messageImagesGrid}>
                                                                        <Image.PreviewGroup>
                                                                            {message.imageUrls.map((url, idx) => (
                                                                                <Image
                                                                                    key={idx}
                                                                                    src={getFilePreviewUrl(url)}
                                                                                    alt={`å›¾ç‰‡æ•°æ®_${idx}`}
                                                                                    className={styles.messageImage}
                                                                                    preview={{
                                                                                        mask: 'é¢„è§ˆ'
                                                                                    }}
                                                                                />
                                                                            ))}
                                                                        </Image.PreviewGroup>
                                                                    </div>
                                                                )}
                                                                <p className={styles.messageText}>{showLoadingBubble ? 'AIè¯†åˆ«ä¸­...' : renderMarkdown(message.content ||'')}</p>
                                                            </div>
                                                        )}
                                                    </div>
                                                </div>
                                            )})}
                                    </div>
                                </div>

                                <div className={styles.statusBar}>
                                    {/* æ–‡ä»¶åˆ—è¡¨æ˜¾ç¤ºåŒºåŸŸ - ç»Ÿä¸€æ¸²æŸ“ï¼Œä¸é‡å¤ */}
                                    {fileList.length > 0 && (
                                        <div className={styles.fileListContainer}>
                                            {fileList.map((file) => (
                                                <div key={file.uid} className={styles.fileItem}>
                                                    {isImageFile(file) ? (
                                                        <Image
                                                            width={32}
                                                            height={32}
                                                            src={getFilePreviewUrl(file)}
                                                            alt={file.name}
                                                            style={{ borderRadius: '2px', objectFit: 'cover' }}
                                                            preview={{
                                                                mask: 'é¢„è§ˆ'
                                                            }}
                                                        />
                                                    ) : (
                                                        <div className={styles.filePreview}>
                                                            <FileTextOutlined className={styles.fileIcon} />
                                                        </div>
                                                    )}
                                                    <div className={styles.fileInfo}>
                                                        <Text className={styles.fileName} ellipsis={{ tooltip: file.name }}>
                                                            {file.name}
                                                        </Text>
                                                    </div>
                                                    <CloseCircleFilled
                                                        className={styles.removeFileButton}
                                                        onClick={() => handleRemoveFile(file)}
                                                    />
                                                </div>
                                            ))}
                                        </div>
                                    )}
                                    {renderInputArea()}
                                </div>
                            </div>

                            <div className={styles.toolbar}>
                                <div className={styles.topButtons}>
                                    <button onClick={() => navigate('/')} className={styles.homeButton}>
                                        <Home/>
                                        <span>è¿”å›</span>
                                    </button>

                                    <button
                                        onClick={handleNewConversation}
                                        className={styles.homeButton}
                                        disabled={loading}
                                    >
                                        <MessageSquarePlus/>
                                        <span>æ–°å¯¹è¯</span>
                                    </button>
                                </div>

                                <div className={styles.toolbarButtons}>
                                    <button
                                        onMouseDown={handleVoiceMouseDown}
                                        onTouchStart={handleVoiceTouchStart}
                                        onTouchMove={handleVoiceTouchMove}
                                        onTouchEnd={handleVoiceTouchEnd}
                                        className={`${getToolbarButtonClasses('voice')} ${voiceStatus === 'recording' ? styles.recording : ''}`}
                                        disabled={loading || isUploading || isVoiceCallActive}
                                    >
                                        <div className={styles.toolbarIconWrapper}>
                                            <Mic />
                                        </div>
                                        <span>è¯­éŸ³</span>
                                    </button>

                                    <button
                                        onClick={isVoiceCallActive ? stopVoiceCall : startVoiceCall}
                                        className={`${styles.voiceCallButton} ${isVoiceCallActive ? styles.active : ''}`}
                                        disabled={loading || isUploading}
                                    >
                                        <div className={styles.toolbarIconWrapper}>
                                            {isVoiceCallActive ? <PhoneOff /> : <Phone />}
                                        </div>
                                        <span>{isVoiceCallActive ? 'ç»“æŸé€šè¯' : 'å®æ—¶é€šè¯'}</span>
                                    </button>

                                    <Upload {...uploadProps} style={{ width: '100%' }}>
                                        <button
                                            onClick={()=>{
                                                stopAudio()
                                            }}
                                            className={getToolbarButtonClasses('file')}
                                        >
                                            <div className={styles.toolbarIconWrapper}>
                                                <FileUp />
                                            </div>
                                            <span>æ–‡ä»¶</span>
                                        </button>
                                    </Upload>

                                    <button onClick={openCamera} className={getToolbarButtonClasses('camera')}>
                                        <div className={styles.toolbarIconWrapper}>
                                            <Camera/>
                                        </div>
                                        <span>æ‹æ‘„</span>
                                    </button>

                                    <button
                                        onClick={stopSpeech}
                                        className={`${styles.toolbarButton} ${styles.stopAudioToolbar}`}
                                        disabled={!isAudioPlaying}
                                    >
                                        <div className={styles.toolbarIconWrapper}>
                                            <StopCircle/>
                                        </div>
                                        <span>åœæ­¢</span>
                                    </button>
                                </div>

                                <div className={styles.volumeCard}>
                                    <Volume2 className={styles.volumeIconHigh} size={14} />
                                    <div className={styles.sliderWrapper}>
                                        <Slider
                                            vertical
                                            min={0}
                                            max={100}
                                            value={audioVolume}
                                            onChange={(value) => setAudioVolume(value as number)}
                                            tooltip={{ formatter: (value) => `${value}%`, placement: 'left' }}
                                        />
                                    </div>
                                    <Volume1 className={styles.volumeIconLow} size={14} />
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <CameraCaptureModal
                visible={cameraModalVisible}
                onClose={closeCamera}
                onCaptured={handleCapturedImage}
            />
        </>
    );
};

export default AIQA;
